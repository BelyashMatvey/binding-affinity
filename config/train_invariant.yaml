seed: 42
output_dir: ${hydra:runtime.output_dir}
logdir: logs/
checkpoint: null

datamodule:
  _target_: binding_affinity.data.datamodule.DataModule
  datadir: data/
  batch_size: 64
  graph_radius: 6
  n_neighbors: 10
  bipartite: true

lightning:
  _target_: binding_affinity.model.lightning.AffinityModel
  model:
    _target_: binding_affinity.model.invariant.InvariantGNN
    node_vocab_size: 100
    node_dim: 32
    edge_dim: 32
    n_layers: 3
    dropout: 0.3

  optimizer_fn:
    _target_: torch.optim.Adam
    _partial_: true
    lr: 0.0001
    weight_decay: 1.0

  loss:
    _target_: torch.nn.MSELoss
    reduction: mean

callbacks:
  model_checkpoint:
    _target_: lightning.pytorch.callbacks.ModelCheckpoint
    monitor: val/PearsonCorrCoef
    mode: max
    dirpath: "${output_dir}/checkpoints"
    verbose: True
    filename: "epoch_{epoch:03d}"
    save_last: True
    save_top_k: 1
    auto_insert_metric_name: False
trainer:
  _target_: lightning.Trainer
  accelerator: auto  # cpu, gpu, mps
  devices: 1
  max_epochs: 200
  log_every_n_steps: 10
  deterministic: true

logger:
  _target_: pytorch_lightning.loggers.tensorboard.TensorBoardLogger
  save_dir: "${output_dir}/tensorboard/"
  name: null
  log_graph: False
  default_hp_metric: True
  prefix: ""
  version: ""

hydra:
  run:
    dir: ${logdir}/runs/${now:%Y-%m-%d}/${now:%H:%M:%S}

  sweep:
    dir: ${logdir}/multiruns/${now:%Y-%m-%d}/${now:%H:%M:%S}/
    subdir: ${hydra.job.override_dirname}
